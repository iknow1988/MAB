Multi-armed bandits (MABs) are a powerful tool in statistical machine learning: they bridge decision
making, control, optimisation and learning; they address practical problems of sequential decision making while
backed by elegant theoretical guarantees; they are often easily implemented, ecient to run, and are used in
many industrial applications; and more subtly they are neither fully supervised nor unsupervised, being partial
labelled by indirect rewards. Exploitation behaviour in MABs optimises short-term rewards by acting greedily
based on current knowledge; but this must be balanced against imprecision in knowledge by exploration; and
when eectively balanced, MABs optimise for long-term reward. In this project, you will work individually to
implement several MAB learners.
